# ğŸ³ Docker Deployment Guide

Run the AI Data Analyst application on any device using Docker!

## ğŸ“‹ Prerequisites

- **Docker Desktop** (includes Docker and Docker Compose)
  - **macOS/Windows:** [Download Docker Desktop](https://www.docker.com/products/docker-desktop/)
  - **Linux:** Install Docker Engine and Docker Compose separately

Verify installation:
```bash
docker --version
docker-compose --version
```

---

## âš¡ Quick Start (3 steps)

### 1. Set Your Gemini API Key

Create a `.env` file in the `backend` directory:

```bash
cd backend
echo "GEMINI_API_KEY=your_api_key_here" > .env
```

Or add it to `docker-compose.yml` directly (line 14).

### 2. Build and Start

From the project root:

```bash
docker-compose up --build
```

### 3. Access the Application

- **Frontend:** http://localhost
- **Backend API:** http://localhost:8000
- **API Docs:** http://localhost:8000/api/docs

**That's it!** ğŸ‰

---

## ğŸ¯ Common Commands

### Start the application
```bash
docker-compose up
```

### Start in background (detached mode)
```bash
docker-compose up -d
```

### Stop the application
```bash
docker-compose down
```

### Stop and remove all data
```bash
docker-compose down -v
```

### Rebuild after code changes
```bash
docker-compose up --build
```

### View logs
```bash
# All services
docker-compose logs -f

# Backend only
docker-compose logs -f backend

# Frontend only
docker-compose logs -f frontend
```

### Check service status
```bash
docker-compose ps
```

### Restart a service
```bash
docker-compose restart backend
docker-compose restart frontend
```

---

## ğŸ“‚ Project Structure

```
ai-data-analyst-app/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile           # Backend container config
â”‚   â”œâ”€â”€ .dockerignore        # Files to exclude
â”‚   â”œâ”€â”€ .env                 # Your API keys (create this)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile           # Frontend container config
â”‚   â”œâ”€â”€ nginx.conf           # Web server config
â”‚   â”œâ”€â”€ .dockerignore        # Files to exclude
â”‚   â””â”€â”€ ...
â””â”€â”€ docker-compose.yml       # Orchestration config
```

---

## ğŸ”§ Configuration

### Environment Variables

#### Backend (.env file)
```env
GEMINI_API_KEY=your_actual_api_key_here
API_HOST=0.0.0.0
API_PORT=8000
DATA_DIR=/app/data
```

#### Frontend (docker-compose.yml)
```yaml
environment:
  - VITE_API_BASE_URL=http://localhost:8000
```

### Port Configuration

Default ports:
- Frontend: `80` (http://localhost)
- Backend: `8000` (http://localhost:8000)

To change ports, edit `docker-compose.yml`:

```yaml
services:
  frontend:
    ports:
      - "3000:80"  # Run on port 3000 instead

  backend:
    ports:
      - "9000:8000"  # Run on port 9000 instead
```

---

## ğŸ’¾ Data Persistence

Project data is stored in a Docker volume named `backend-data`. This means:

âœ… **Data persists** between container restarts
âœ… **Projects remain** when you stop/start containers
âœ… **Data is lost** only if you run `docker-compose down -v`

### Backup Data

```bash
# Create backup
docker run --rm -v ai-data-analyst-app_backend-data:/data -v $(pwd):/backup alpine tar czf /backup/data-backup.tar.gz /data

# Restore backup
docker run --rm -v ai-data-analyst-app_backend-data:/data -v $(pwd):/backup alpine tar xzf /backup/data-backup.tar.gz -C /
```

---

## ğŸš€ Deployment to Another Device

### Option 1: Using Docker Hub (Recommended)

**On your current device:**

```bash
# Build and tag images
docker build -t yourusername/ai-analyst-backend:latest ./backend
docker build -t yourusername/ai-analyst-frontend:latest ./frontend

# Push to Docker Hub
docker push yourusername/ai-analyst-backend:latest
docker push yourusername/ai-analyst-frontend:latest
```

**On the new device:**

```bash
# Pull and run
docker pull yourusername/ai-analyst-backend:latest
docker pull yourusername/ai-analyst-frontend:latest
docker-compose up
```

### Option 2: Export/Import Images

**On your current device:**

```bash
# Save images to tar files
docker save -o backend.tar ai-data-analyst-app-backend
docker save -o frontend.tar ai-data-analyst-app-frontend

# Transfer backend.tar and frontend.tar to the new device
```

**On the new device:**

```bash
# Load images
docker load -i backend.tar
docker load -i frontend.tar

# Run
docker-compose up
```

### Option 3: Clone Repository

**On any device:**

```bash
# Clone the repository
git clone https://github.com/tarangdeep-goel-by/ai-data-analyst-v2.git
cd ai-data-analyst-v2

# Checkout React branch
git checkout react-frontend

# Add your API key
cd backend
echo "GEMINI_API_KEY=your_key" > .env
cd ..

# Start
docker-compose up --build
```

---

## ğŸ› Troubleshooting

### Port Already in Use

**Error:** `Bind for 0.0.0.0:8000 failed: port is already allocated`

**Solution:**
```bash
# Find and kill process on port 8000
lsof -ti:8000 | xargs kill -9

# Or change the port in docker-compose.yml
```

### Gemini API Not Configured

**Error:** `"gemini_configured": false`

**Solution:**
```bash
# Check if .env file exists
cat backend/.env

# If not, create it
cd backend
echo "GEMINI_API_KEY=your_actual_key" > .env

# Rebuild
docker-compose up --build
```

### Cannot Connect to Backend

**Error:** `Failed to load projects` or CORS errors

**Solution:**
```bash
# Check backend is running
docker-compose ps

# Check backend logs
docker-compose logs backend

# Restart backend
docker-compose restart backend
```

### Build Fails

**Error:** Various build errors

**Solution:**
```bash
# Clean everything and rebuild
docker-compose down -v
docker system prune -a
docker-compose up --build
```

### Frontend Shows Blank Page

**Solution:**
```bash
# Check frontend logs
docker-compose logs frontend

# Rebuild frontend
docker-compose up --build frontend
```

---

## ğŸ” Health Checks

Both services have built-in health checks:

```bash
# Check backend health
curl http://localhost:8000/health

# Check frontend health
curl http://localhost/health

# View health status in Docker
docker-compose ps
```

---

## ğŸ›‘ Stopping and Cleanup

### Stop without removing data
```bash
docker-compose down
```

### Stop and remove containers, networks
```bash
docker-compose down
```

### Stop and remove EVERYTHING (including data)
```bash
docker-compose down -v
```

### Remove all unused Docker resources
```bash
docker system prune -a
```

---

## ğŸ“Š Resource Usage

### View resource usage
```bash
docker stats
```

### Limit resources (docker-compose.yml)
```yaml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
```

---

## ğŸ” Security Best Practices

1. **Never commit `.env` files** with real API keys
2. **Use environment variables** for sensitive data
3. **Keep images updated**:
   ```bash
   docker-compose pull
   docker-compose up -d
   ```
4. **Scan images for vulnerabilities**:
   ```bash
   docker scan ai-data-analyst-app-backend
   ```

---

## ğŸŒ Production Deployment

For production, consider:

1. **Use a reverse proxy** (nginx, Traefik)
2. **Enable HTTPS** with Let's Encrypt
3. **Set up monitoring** (Prometheus, Grafana)
4. **Use Docker Swarm or Kubernetes** for orchestration
5. **Configure automatic backups**
6. **Set resource limits**
7. **Use production-grade WSGI server** (Gunicorn) instead of development server

---

## ğŸ“š Additional Resources

- [Docker Documentation](https://docs.docker.com/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Docker Hub](https://hub.docker.com/)
- [Best Practices for Writing Dockerfiles](https://docs.docker.com/develop/dev-best-practices/)

---

## ğŸ†˜ Need Help?

If you encounter issues:

1. Check logs: `docker-compose logs`
2. Verify services: `docker-compose ps`
3. Check health: `curl http://localhost:8000/health`
4. Review this guide
5. Check GitHub issues

---

## âœ… Verification Checklist

After deployment, verify:

- [ ] Both containers are running: `docker-compose ps`
- [ ] Backend health check passes: `curl http://localhost:8000/health`
- [ ] Frontend loads: Open http://localhost in browser
- [ ] Can upload CSV file
- [ ] Can create chat and send query
- [ ] Data persists after restart: `docker-compose restart`

---

**Happy Dockerizing! ğŸ³**
